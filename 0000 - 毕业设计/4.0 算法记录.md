

# 0316 安装过程记录
[【手把手带你实战YOLOv5-入门篇】YOLOv5 环境安装_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1G24y1G7qm/?buvid=XX7A39471D675D8F0A4AE55593F3A508A71AA&is_story_h5=false&mid=JrhLaIG%2F4%2FkK1riSfWjujQ%3D%3D&p=1&plat_id=114&share_from=ugc&share_medium=android&share_plat=android&share_session_id=3c6fc000-ea03-41ff-9e2b-af2144aff341&share_source=QQ&share_tag=s_i&timestamp=1678961472&unique_k=trjOr4r&up_id=21060026)


![[201903040009images.aasts/image-20230316144912132.png]]

![[201903040009images.aasts/image-20230316160849595.png]]
![[201903040009images.aasts/image-20230316164511005.png]]


![[201903040009images.aasts/image-20230316170305065.png]]

![[201903040009images.aasts/image-20230316170509898.png]]


![[201903040009images.aasts/image-20230316170626649.png]]

![[201903040009images.aasts/image-20230316171012299.png]]

![[201903040009images.aasts/image-20230316171016465.png]]

![[201903040009images.aasts/image-20230316171321149.png]]


![[201903040009images.aasts/image-20230316171330457.png]]

![[201903040009images.aasts/image-20230316171912849.png]]

这样下的是CPU版本的 CPU训练

![[201903040009images.aasts/image-20230316172246052.png]]


![[201903040009images.aasts/image-20230316172353492.png]]

pip install -r requirements.txt


pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple/


D:\b_installpath\miniconda3\

![[201903040009images.aasts/image-20230316182321684.png]]


![[201903040009images.aasts/image-20230316182618406.png]]

![[201903040009images.aasts/image-20230316182832142.png]]

## 摄像头
K210 摄像头
![[201903040009images.aasts/image-20230313163257707.png]]
![[201903040009images.aasts/image-20230313195044100.png]]




## 安装torch 1.8.2 
![[201903040009images.aasts/image-20230317124514909.png]]



![[201903040009images.aasts/image-20230317111728871.png]]


![[201903040009images.aasts/image-20230317111724860.png]]

![[201903040009images.aasts/image-20230317111853184.png]]


![[201903040009images.aasts/image-20230317112510706.png]]

![[201903040009images.aasts/image-20230317112634147.png]]

![[201903040009images.aasts/image-20230317112701123.png]]

![[201903040009images.aasts/image-20230317112737837.png]]
![[201903040009images.aasts/image-20230317112750107.png]]

![[201903040009images.aasts/image-20230317112827885.png]]



## VS打开运行

![[201903040009images.aasts/image-20230317113758530.png]]

## 关键参数 
### weights
![[201903040009images.aasts/image-20230317114107820.png]]

`第二个 一般的版本`
python detect.py --weights yolov5s.pt  


![[201903040009images.aasts/image-20230317114017807.png]]

用高级版本 明显速度变慢了
![[201903040009images.aasts/image-20230317114244847.png]]

![[201903040009images.aasts/image-20230317114515393.png]]



---
### source
![[201903040009images.aasts/image-20230317114609209.png]]

python detect.py --weights yolov5s.pt --source data/images/bus.jpg

![[201903040009images.aasts/image-20230317114905608.png]]



![[201903040009images.aasts/image-20230317115139092.png]]
![[201903040009images.aasts/image-20230317115118826.png]]


### 框的多少
0.8置信度以上的才显示框
python detect.py --weights yolov5s.pt   --conf-thres 0.8

越低框越少
![[201903040009images.aasts/image-20230317120419452.png]]



越低框越多
![[201903040009images.aasts/image-20230317120937090.png]]



### 嵌入很麻烦
![[201903040009images.aasts/image-20230317121144286.png]]


先安装jupyter
pip install jupyterlab
![[201903040009images.aasts/image-20230317121548807.png]]


根目录新建文件
hub_detect.ipynb
![[201903040009images.aasts/image-20230317121713962.png]]





```
import torch

# Model
model = torch. hub.1oad("./", "yolov5s", source= "local")

# Images
img = "./data/ images/ zidane.jpg"

#Inference
results = model(img)

# Results
results. show( )

```


![[201903040009images.aasts/image-20230317122145373.png]]



### gradio页面
![[201903040009images.aasts/image-20230317150329706.png]]


### ipcam
[(3条消息) yolo-v5连接手机摄像头实时检测的步骤_怎么把实时屏幕传输给yolov5_世由心生的博客-CSDN博客](https://blog.csdn.net/gongkeguo/article/details/121609311)

[几分钟实现YOLO_V5从0到1调用手机摄像头实时目标检测_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1kR4y147pR/?spm_id_from=333.337.search-card.all.click&vd_source=055c0f614d8dec2c3bf7aff0db5e54cb)

地址为分享里面的局域网地址

python detect.py --weights yolov5s.pt  

python detect.py --weights yolov5s.pt --source http://admin:admin@192.168.43.1:8081


python detect.py --source http://cbxg:cbxg@192.168.135.74:8081   
本机摄像头：python detect.py --source 0 

![[201903040009images.aasts/image-20230317160022837.png]]

![[201903040009images.aasts/image-20230317160103328.png]]





## YOLO算法数据集制作：利用Python将视频切分成图片

目标检测YOLO算法数据集制作：利用Python将视频切分成图片




# 0414 YOLO 一些修改策略 0414及之前

## 输出的txt yolov5 label格式说明

```python
cmd = r'd: && python D:\Desktop\yolov5-7.0\detect.py --weights yolov5s.pt --source D:\Desktop\IOT_SoftWare\screenshot.jpg --save-txt'
```

![](201903040009images.aasts/image-20230415112739020.png)

5个值分别为 ：  
`标签编号` `box中心x` `box中心y` `宽` `高`  
分别对应  
`label` `x_center` `y_center` `width` `height`  
label值由训练时设定  
比如训练时为`'Car', 'Cyclist', 'Pedestrian'`  
那么

```
0对应'Car'
1对应'Cyclist'
2对应'Pedestrian'`
```

后4个值都在0-1之间，分别为box中心的x、box中心的y、图像宽、图像高。

```
            box_x_min # 左上角横坐标 
            box_y_min # 左上角纵坐标
            box_x_max # 右下角横坐标
            box_y_max # 右下角纵坐标

            x_center = float(box_x_min + box_x_max) / (2 * picture_width)
            y_center = float(box_y_min + box_y_max) / (2 * picture_height)
            width = float(box_x_max - box_x_min) /  picture_width
            height = float(box_y_max - box_y_min) /  picture_height
```

## yolov5官方标签对应属性挑选  coco128.yaml👍

随便打开一个输出的txt文件，可以看到是个2行5列的矩阵，这表明检测到了2个目标，每一行表示对应目标的属性，第一列是标签名（就是训练的时候的类别标签序号，这里采用官方的yolov5s.pt进行检测，<font color="#ffff00">0对应‘person’</font>），后面四列依次为xcenter ycenter w h（框中心的x、y坐标，以及框的宽、高），均为归一化数值。

原文链接：https://blog.csdn.net/Albert_yeager/article/details/129767999

---

[[yolov5] yolo的数据标签格式_yolo格式的标签_一骑红尘荔枝来的博客-CSDN博客](https://blog.csdn.net/condom10010/article/details/128164211)
![](201903040009images.aasts/image-20230415114445838.png)

`筛选`
  0: 人   1: 自行车   2: 汽车   3: 摩托车   5: 公共汽车   9: 交通灯  13: 长椅   16: 狗
 
---

  0: 人
  1: 自行车
  2: 汽车
  3: 摩托车
  4: 飞机
  5: 公共汽车
  6: 火车
  7: 卡车
  8: 船只
  9: 交通灯
  10: 消防栓
  11: 停车标志
  12: 停车计时器
  13: 长椅
  14: 鸟
  15: 猫
  16: 狗
  17: 马
  18: 绵羊
  19: 牛
  20: 大象
  21: 熊
  22: 斑马
  23: 长颈鹿
  24: 背包
  25: 雨伞
  26: 手提包
  27: 领带
  28: 手提箱
  29: 飞盘
  30: 滑雪板
  31: 滑雪板
  32: 运动球
  33: 风筝
  34: 棒球棒
  35: 棒球手套
  36: 滑板
  37: 冲浪板
  38: 网球拍
  39: 酒瓶
  40: 酒杯
  41: 杯子
  42: 叉子
  43: 刀
  44: 勺子
  45: 碗
  46: 香蕉
  47: 苹果
  48: 三明治
  49: 橙子
  50: 西兰花
  51: 胡萝卜
  52: 热狗
  53: 披萨
  54: 甜甜圈
  55: 蛋糕
  56: 椅子
  57: 沙发
  58: 盆栽
  59: 床
  60: 餐桌
  61: 厕所
  62: 电视机
  63: 笔记本电脑
  64: 鼠标
  65: 遥控器
  66: 键盘
  67: 手机
  68: 微波炉
  69: 烤箱
  70: 烤面包机
  71: 水槽
  72: 冰箱
  73: 书
  74: 钟表
  75: 花瓶
  76: 剪刀
  77: 泰迪熊
  78: 吹风机
  79: 牙刷










## txt文件默认是累积往下的 修改 👍👍 
---
updated: 2023-04-15 12:37

我这里加上了 --exist-ok 确保了每次识别出来的图片会进行覆盖，但label的txt文件不会覆盖，txt会累计往下写
因此需要对源码进行修改

```
python D:\Desktop\yolov5-7.0\detect.py --weights yolov5s.pt --source data/images/bus.jpg --save-txt  --class 0 2 3  --exist-ok
```


```
python D:\Desktop\yolov5-7.0\detect.py --weights yolov5s.pt --source D:\Desktop\IOT_SoftWare\screenshot.jpg --save-txt --class 0 2 3  --exist-ok
```

`最终的`
```
python D:\Desktop\yolov5-7.0\detect.py --weights yolov5s.pt --source D:\Desktop\IOT_SoftWare\screenshot.jpg --save-txt --class 0 1 2 3 5 9 13 16  --exist-ok
```

![](201903040009images.aasts/image-20230415121024129.png)

修改yolo源代码：
[yolov5 --save-txt 生成的txt怎么设置为覆盖而不是追加到txt中？-编程语言-CSDN问答](https://ask.csdn.net/questions/7766446)

detect.py函数的 160-166 原来的a且在for循环之内

```
                # Write results
                for *xyxy, conf, cls in reversed(det):
                    if save_txt:  # Write to file
                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh
                        line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format
                        with open(f'{txt_path}.txt', 'w') as f: # txt输出文件 a是追加写，w是覆盖写
                            f.write(('%g ' * len(line)).rstrip() % line + '\n')
```

![](201903040009images.aasts/image-20230415121644819.png)



----
修改后
![](201903040009images.aasts/image-20230415122511065.png)

160-167行
```
                # Write results
            with open(f'{txt_path}.txt', 'w') as f: # txt输出文件 a是追加写，w是覆盖写
                for *xyxy, conf, cls in reversed(det):
                    if save_txt:  # Write to file
                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh
                        line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format
                        
                        f.write(('%g ' * len(line)).rstrip() % line + '\n')
```

运行结果：改完之后不论图片还是txt都是会覆盖的
![](201903040009images.aasts/image-20230415123004677.png)


换图片之后也会自动覆盖：
![](201903040009images.aasts/image-20230415123218254.png)

![](201903040009images.aasts/image-20230415123227980.png)




---
整体流程记录

`yolov5 --save-txt 生成的txt怎么设置为覆盖而不是追加到txt中？`
用yolov5 detect.py进行训练数据时，需要实时对传入的相同名字的图片进行训练，
请问当--save-txt参数为True时，如果照片名相同，每次新的坐标数据都是追加到原来生成的txt中
导致读取此文本时，存在上次训练时的旧的数据。
我设置了--exist-ok为True，每次识别出来的图片会进行覆盖，但label的txt文件不会覆盖，
怎么样才能设置每次生成的txt是覆盖原来的呢？

答：搜索下txt\_path,然后将这里的a换成w，a是追加写，w是覆盖写
![img](1681532835.assets/1681532835-abe63461130746acfd8d8fc53662e52d.png)

问：请问换成w的话，如果一张图片有多个特征值的话，生成的txt里只会记录最后一个，有没有办法使得将一张图片里所有标签都写入txt后再识别下一张图片时覆盖掉原来的呢
   
答：把这句提到for循环外面去啊

太感谢大佬了！(っ'-')╮=͟͟͞͞






## 只预测指定类别

```
--save-txt            save results to *.txt    #将预测的bounding box保存为txt文件
--save-crop           save cropped prediction boxes   #将预测的bounding box截取出来
 --classes CLASSES [CLASSES ...]    #只预测指定类别
 
 classes=None,  # filter by class: --class 0, or --class 0 2 3
```



```
cmd = r'd: && python D:\Desktop\yolov5-7.0\detect.py --weights yolov5s.pt --source D:\Desktop\IOT_SoftWare\screenshot.jpg --save-txt  --class 0 2 3 '
```



## yolo将返回值results写入txt 


# 0415 融合截图 cmd txt输出测试 重大突破😍
---
updated: 2023-04-15 

## 测试截图

![](201903040009images.aasts/image-20230415185540231.png)


以抓取wps打开的图片窗口为例
![](201903040009images.aasts/image-20230415185824704.png)

![](201903040009images.aasts/image-20230415185903976.png)

![](201903040009images.aasts/image-20230415185922313.png)

## 代码保存
![](201903040009images.aasts/image-20230416231544729.png)


```python
# 融合抓图 识别 输出识别信息三个部分
# 2023.04.15 created by 徐梦昊
# -*- coding: UTF-8 -*-
# cmd依赖
import os, sys, re

# 截图指定hwnd的窗口 并截图保存
# 先引入依赖包 pip install PyQt5
# 最开始运行的时候先注释掉下面的hwnd 以下的程序 因为hwnd我要先跑上面的程序获取 可以先放开下一行hwnd万金油运行一遍 这样不用注释
# 截图依赖
import win32gui
import win32con
from PyQt5.QtWidgets import QApplication
from PIL import ImageGrab


# 抓取指定的窗口 截屏保存
def screenshot_f():
    # hwnd_title = dict()

    # def get_all_hwnd(hwnd, mouse):
    #     if win32gui.IsWindow(hwnd) and win32gui.IsWindowEnabled(hwnd) and win32gui.IsWindowVisible(hwnd):
    #         hwnd_title.update({hwnd: win32gui.GetWindowText(hwnd)})

    
    # win32gui.EnumWindows(get_all_hwnd, 0)
    # # print(hwnd_title.items()) 打印的是hwnd值和对应的Title
    # for h, t in hwnd_title.items():
    #     if t != "":
    #         print(h, t)
    

    hwnd = 133042 #  上面获取后自己填入对应窗口的hwnd 第一列
    print(hwnd)

    win32gui.ShowWindow(hwnd, win32con.SW_RESTORE)  # 强行显示界面后才好截图
    win32gui.SetForegroundWindow(hwnd)  # 将窗口提到最前
    #  裁剪得到全图
    game_rect = win32gui.GetWindowRect(hwnd)
    src_image = ImageGrab.grab(game_rect)
    # src_image.show() #截图完用系统默认图片查看器打开 可以不打开
    src_image.save("screenshot.jpg")


# yolo 的cmd调用 生成覆盖的txt文本文件
def getcmd_f():
	'''
	处理图片
	:param url:图片地址
	:return: 图片中的人数
	'''
	cmd = r'd: && python D:\Desktop\yolov5-7.0\detect.py --weights yolov5s.pt --conf-thres 0.6 --source D:\Desktop\IOT_SoftWare\screenshot.jpg --save-txt --class 0 1 2 3 5 9 13 16  --exist-ok'
	text = os.popen(cmd).readlines()
	print(text)


def txt_spilt_f():
    f=open("D:/Desktop/yolov5-7.0/runs/detect/exp/labels/screenshot.txt","r", encoding = 'utf-8',errors='ignore')
    txt = [0,0,0,0,0,0,0,0]
    for line in f:
        # print(line.split(' ')[0]) # 一步到位
        # a = line.split(' ')[0] # a为以空格分隔之后的首个元素  仍为字符类型
        a = int(line.split(' ')[0]) # a为以空格分隔之后的首个元素 
        # print(a)
        if a == 0:# 人
            txt[0] = txt[0] +1
        if a == 1: # 自行车
            txt[1] = txt[1] +1
        if a == 2: # 汽车
            txt[2] = txt[2] +1
        if a == 3: # 摩托车
            txt[3] = txt[3] +1
        if a == 5: # 公共汽车
            txt[4] = txt[4] +1
        if a == 9: # 交通灯
            txt[5] = txt[5] +1
        if a == 13: # 长椅
            txt[6] = txt[6] +1
        if a == 16: # 狗
            txt[7] = txt[7] +1

    message = ""
    if txt[0] != 0:# 人
        message = str(txt[0]) +"个人 "
    if txt[1] != 0: # 自行车
        message = message +  str(txt[1]) +"辆自行车 "
    if txt[2] != 0: # 汽车
        message = message +  str(txt[2]) +"辆汽车 "
    if txt[3] != 0: # 摩托车
        message = message +  str(txt[3]) +"辆摩托车 "
    if txt[4] != 0: # 公共汽车
        message = message +  str(txt[4]) +"辆公共汽车 "
    if txt[5] != 0: # 交通灯
        message = message +  str(txt[5]) +"个交通灯 "
    if txt[6] != 0: # 长椅
        message = message +  str(txt[6]) +"个长椅 "
    if txt[7] != 0: # 狗
        message = message +  str(txt[7]) +"条狗 "
    message1 = "前方共有"+ message
    print (message1)

	

if __name__ == '__main__':
    screenshot_f()
    getcmd_f()
    txt_spilt_f()
```



# 0416 融合接受信息 发布识别状况 重大突破😍
---
updated: 2023-04-16 18:01

融合后接连遇到两个问题
## error(0, ‘SetForegroundWindow‘, ‘No error message is available‘)
[error(0, ‘SetForegroundWindow‘, ‘No error message is available‘)_reb0rn初代的博客-CSDN博客](https://blog.csdn.net/qq_34195441/article/details/109177402)

原来代码出现error(0, 'SetForegroundWindow', 'No error message is available')错误，

解决方法：加上


```python
pythoncom.CoInitialize()
shell = win32com.client.Dispatch("WScript.Shell")
shell.SendKeys('%')
```


原文链接：https://blog.csdn.net/qq_34195441/article/details/109177402
![](201903040009images.aasts/image-20230416175812750.png)

## 加入上述三句后no module named win32com.client 报错

[no module named win32com.client 报错 - 可爱的黑精灵 - 博客园 (cnblogs.com)](https://www.cnblogs.com/chenjy1225/p/14461819.html)
![](201903040009images.aasts/image-20230416175926332.png)
修改引入的依赖
![](201903040009images.aasts/image-20230416180006246.png)

## 最后实现的效果  演示
1. 运行代码
![](201903040009images.aasts/image-20230416180623730.png)

2. 已经订阅 且持续监听当中
![](201903040009images.aasts/image-20230416180700289.png)

3. mqtt.fx模拟按键按下 发送消息字符“1”
![](201903040009images.aasts/image-20230416180733582.png)

4. python控制台显示识别结果 
![](201903040009images.aasts/image-20230416180816004.png)

5. yolo项目中输出的图片和txt均已经覆盖更新
![](201903040009images.aasts/image-20230416180901857.png)

6. mqttfx模拟接收的图像识别信息 已经正确收到
![](201903040009images.aasts/image-20230416180951065.png)

7. 下一步将要做的
   主板订阅该接收识别信息的主题
   主板连接语音模块对该信息进行播报【待做 下一步】
   最终实现 我按下主板的按钮 就播放我眼前景象的图像识别信息



## 服务器源码
![](201903040009images.aasts/image-20230416231632936.png)


主要功能：
1. 订阅主板按键对应的主题
2. 监听按键按下 模拟发送到该主题字符“1”
3. 监听到之后，接连调用 抓屏 、yolo识别、输出txt文本的识别
4. 将识别处理之后的结果字符串发送到指定的主题（该主题用于 主板接收到之后进行语音播报 <font color="#ffff00">待实现语音</font>）
```python
# python3.6
# -*- coding: utf-8 -*-
import paho.mqtt.client as mqtt
import random

# -*- coding: UTF-8 -*-
# cmd依赖
import os, sys, re

# 截图指定hwnd的窗口 并截图保存
# 先引入依赖包 pip install PyQt5
# 最开始运行的时候先注释掉下面的hwnd 以下的程序 因为hwnd我要先跑上面的程序获取 可以先放开下一行hwnd万金油运行一遍 这样不用注释
# 截图依赖
import win32gui
import win32con
from PyQt5.QtWidgets import QApplication
from PIL import ImageGrab

# import win32com
import win32com.client
import pythoncom


broker = 'broker.emqx.io'
port = 1883
topic_button = "cc36e70148924ef2bb2e1d477c24675f_button"
topic_mp3 = "cc36e70148924ef2bb2e1d477c24675f_mp3"
# generate client ID with pub prefix randomly
client_id = f'python-mqtt-{random.randint(0, 100)}'


# 订阅函数
class MqttRoad(object):
 
    def __init__(self, mqtt_host, mqtt_port, mqtt_keepalive):
        super(MqttRoad, self).__init__()
        client = mqtt.Client()
        client.on_connect = self.on_connect
        client.on_message = self.on_message
        client.on_publish = self.on_publish
        client.connect(mqtt_host, mqtt_port, mqtt_keepalive)  # 600为keepalive的时间间隔
        client.loop_forever()  # 保持连接
 
    def on_connect(self, client, userdata, flags, rc):
        print("Connected with result code: " + str(rc))
        # 订阅
        client.subscribe(topic_button)
 
 
    def on_message(self, client, userdata, msg):
        print("on_message topic:" + msg.topic + " message:" + str(msg.payload.decode('utf-8')))
        strmqtt = str(msg.payload.decode('utf-8'))
        if strmqtt == "1":
            print("接收到按键请求 请求发布画面识别的语音播报")
            screenshot_f()
            print("tag1")
            getcmd_f()
            print("tag2")
            txt_spilt_f()
            print("tag3")
            publish()
            print("tag4")
        else:
            print("未收到正确按键请求 占空用")
        
 
    #   订阅回调
    def on_subscribe(self, client, userdata, mid, granted_qos):
        print("On Subscribed: qos = %d" % granted_qos)
        pass
 
    #   取消订阅回调
    def on_unsubscribe(self, client, userdata, mid):
        # print("取消订阅")
        print("On unSubscribed: qos = %d" % mid)
        pass
 
    #   发布消息回调
    def on_publish(self, client, userdata, mid):
        # print("发布消息")
        print("On onPublish: qos = %d" % mid)
        pass
 
    #   断开链接回调
    def on_disconnect(self, client, userdata, rc):
        # print("断开链接")
        print("Unexpected disconnection rc = " + str(rc))
        pass
 
# 发布函数
def publish():
    def on_connect(client, userdata, flags, rc):
        print ("链接")
        print("Connected with result code: " + str(rc))
    
    
    def on_message(client, userdata, msg):
        print ("消息内容")
        print(msg.topic + " " + str(msg.payload))
    
    
    #   订阅回调
    def on_subscribe(client, userdata, mid, granted_qos):
        print ("订阅")
        print("On Subscribed: qos = %d" % granted_qos)
        pass
    
    
    #   取消订阅回调
    def on_unsubscribe(client, userdata, mid, granted_qos):
        print ("取消订阅")
        print("On unSubscribed: qos = %d" % granted_qos)
        pass
    
    
    #   发布消息回调
    def on_publish(client, userdata, mid):
        print ("发布消息")
        print("On onPublish: qos = %d" % mid)
        pass
    
    
    #   断开链接回调
    def on_disconnect(client, userdata, rc):
        print ("断开链接")
        print("Unexpected disconnection rc = " + str(rc))
        pass
    
    
    client = mqtt.Client()
    client.on_connect = on_connect
    client.on_message = on_message
    client.on_publish = on_publish
    client.on_disconnect = on_disconnect
    client.on_unsubscribe = on_unsubscribe
    client.on_subscribe = on_subscribe
    client.connect(broker, 1883, 600) # 600为keepalive的时间间隔

    # client.publish(topic_mp3, payload='前方共有1个人 3辆汽车 1条狗 ', qos=0, retain=False)
    client.publish(topic_mp3, payload = message1, qos=0, retain=False)
    


# 抓取指定的窗口 截屏保存
def screenshot_f():

    hwnd = 133042 #  上面获取后自己填入对应窗口的hwnd 第一列
    print(hwnd)

    win32gui.ShowWindow(hwnd, win32con.SW_RESTORE)  # 强行显示界面后才好截图
    # 融合后加入以下三行才行的
    pythoncom.CoInitialize()
    shell = win32com.client.Dispatch("WScript.Shell")
    shell.SendKeys('%')
    win32gui.SetForegroundWindow(hwnd)  # 将窗口提到最前
    #  裁剪得到全图
    game_rect = win32gui.GetWindowRect(hwnd)
    src_image = ImageGrab.grab(game_rect)
    # src_image.show() #截图完用系统默认图片查看器打开 可以不打开
    src_image.save("screenshot.jpg")


# yolo 的cmd调用 生成覆盖的txt文本文件
def getcmd_f():
	'''
	处理图片
	:param url:图片地址
	:return: 图片中的人数
	'''
	cmd = r'd: && python D:\Desktop\yolov5-7.0\detect.py --weights yolov5s.pt --conf-thres 0.6 --source D:\Desktop\IOT_SoftWare\screenshot.jpg --save-txt --class 0 1 2 3 5 9 13 16  --exist-ok'
	text = os.popen(cmd).readlines()
	print(text)

# txt文本信息处理
def txt_spilt_f():
    f=open("D:/Desktop/yolov5-7.0/runs/detect/exp/labels/screenshot.txt","r", encoding = 'utf-8',errors='ignore')
    txt = [0,0,0,0,0,0,0,0]
    for line in f:
        # print(line.split(' ')[0]) # 一步到位
        # a = line.split(' ')[0] # a为以空格分隔之后的首个元素  仍为字符类型
        a = int(line.split(' ')[0]) # a为以空格分隔之后的首个元素 
        # print(a)
        if a == 0:# 人
            txt[0] = txt[0] +1
        if a == 1: # 自行车
            txt[1] = txt[1] +1
        if a == 2: # 汽车
            txt[2] = txt[2] +1
        if a == 3: # 摩托车
            txt[3] = txt[3] +1
        if a == 5: # 公共汽车
            txt[4] = txt[4] +1
        if a == 9: # 交通灯
            txt[5] = txt[5] +1
        if a == 13: # 长椅
            txt[6] = txt[6] +1
        if a == 16: # 狗
            txt[7] = txt[7] +1

    message = ""
    if txt[0] != 0:# 人
        message = str(txt[0]) +"个人 "
    if txt[1] != 0: # 自行车
        message = message +  str(txt[1]) +"辆自行车 "
    if txt[2] != 0: # 汽车
        message = message +  str(txt[2]) +"辆汽车 "
    if txt[3] != 0: # 摩托车
        message = message +  str(txt[3]) +"辆摩托车 "
    if txt[4] != 0: # 公共汽车
        message = message +  str(txt[4]) +"辆公共汽车 "
    if txt[5] != 0: # 交通灯
        message = message +  str(txt[5]) +"个交通灯 "
    if txt[6] != 0: # 长椅
        message = message +  str(txt[6]) +"个长椅 "
    if txt[7] != 0: # 狗
        message = message +  str(txt[7]) +"条狗 "
    global message1 
    message1= "前方共有"+ message
    print (message1)

 
if __name__ == '__main__':
    MqttRoad(broker, 1883, 600)

```


# 0416 硬件按键触发算法检测 收到发布的检测结果 😍 还差语音播报
## 测试结果截图
![](201903040009images.aasts/image-20230416222212967.jpeg)


![](201903040009images.aasts/image-20230416222219463.jpeg)

![](201903040009images.aasts/image-20230416222225037.jpeg)
![](201903040009images.aasts/image-20230416225540752.png)

![](201903040009images.aasts/image-20230416225905079.png)


## 完整流程 演示
1. 按下按键 在这里以杜邦线短接地为模拟 然后松开 开发板检测到会发送一个特定的字符串”1“到主题
![](201903040009images.aasts/image-20230416224551266.png)
2. 开发板的串口显示 

![](201903040009images.aasts/image-20230416224439526.png)

3. python后台检测到指定字符串之后 调用一连串我写好的方法 将检测的最终结果发布出去
![](201903040009images.aasts/image-20230416224738987.png)


4. 开发板的一端接收到主题发来的消息 收到检测结果
![](201903040009images.aasts/image-20230416224759545.png)
## 硬件代码

```c
#include <ESP8266WiFi.h>
#include <PubSubClient.h>
#include "Timer.h"
//#include <SimpleDHT.h> //温湿度
#include "pinMapping.h" //引脚定义 直接引用Dx
WiFiClient espClient;
PubSubClient client(espClient);
Timer t;

// WiFi 
const char* ssid = "cbxg";
const char* password = "12345678";

// MQTT Broker
const char *mqtt_broker = "broker.emqx.io";
const char *topic1 = "cc36e70148924ef2bb2e1d477c24675f_mp3";//终端收 效应器从该主题接收指令 接收识别信息
const char *topic2 = "cc36e70148924ef2bb2e1d477c24675f_button";//终端发 按键之后发送1
const char *mqtt_username = "root";
const char *mqtt_password = "root0410";
const int mqtt_port = 1883;

//// 超声波 四个引脚 D2 D1 GND 3V3
//// define ultrasonic signal receiver pin  ECHO to D2  GPIO4
//int ECHOPin = D2;  
//// define ultrasonic signal transmitter pin  TRIG to D1  GPIO5
//int TRIGPin = D1;  

//传感器收集变量存储 定义变量
int utlDistance;  //超声波距离 变量存储
double waterHigh;//存储水位
int lightIntensity;//存储光照强度0~99

//三个反应模块 引脚定义
//int ledPinUlt = D3; //超声波距离预警灯光 保留震动用
//int ledPinWater = D4;  //水位过高震动用
int ledPinLight = D3;  //光照过低 灯光点亮提醒路人

int LED = D6;  //用于远程操控灯光  效应器

long lastMsg = 0; //定时器标头

int KEY=D5;//KEY对应D5 
char flag=1;


////////////////////////setup函数/////////////////////////////////////
void setup() {
// 用于串口通信速率设置
    Serial.begin(115200);

//用于引脚模式设置
//    //远程控制的灯光 设置为输出模式
//    pinMode(LED, OUTPUT);  
//
//    //本地震动1 超声波过近震动 设置为输出模式
//    pinMode(ledPinUlt, OUTPUT);  
//
//    //本地震动2 水位过高震动 设置为输出模式
//    pinMode(ledPinWater, OUTPUT);  

    //本地光照3 光照过低 点亮 设置为输出模式
    pinMode(ledPinLight,OUTPUT);
  
//    //超声波传感器 两个引脚定义 一个输入 一个输出
//    pinMode(ECHOPin, INPUT); // Sets the echoPin as an Input
//    pinMode(TRIGPin, OUTPUT);// Sets the trigPin as an Output

    //发送邮件的按键
    pinMode(KEY,INPUT_PULLUP);//将GPIO14 D5 按键设置为上拉输入模式
  
//用于连接wifi
    WiFi.begin(ssid, password);
    while (WiFi.status() != WL_CONNECTED) {
        delay(500);
        Serial.println("Connecting to WiFi..");
    }
    Serial.println("Connected to the WiFi network");
	  Serial.println("IP 地址: ");
    Serial.println(WiFi.localIP());
  
  
//用于连接mqtt服务代理商
    client.setServer(mqtt_broker, mqtt_port);
    client.setCallback(callback);
    while (!client.connected()) {
        //用mac地址区分唯一ip
        String client_id = "esp8266-client-";
        client_id += String(WiFi.macAddress());
        //输出唯一mac服务地址
        Serial.println("--------Start - connects states ----------");
        Serial.printf("The client %s connects to the public mqtt broker\n", client_id.c_str());
        if (client.connect(client_id.c_str(), mqtt_username, mqtt_password)) {
            Serial.println("Public emqx mqtt broker connected");
        } else {
            Serial.print("failed with state ");
            Serial.print(client.state());
            delay(2000);
        }
        Serial.println("--------End - connects states ----------");
    }
  
  
//MQTT永久订阅以及首个发布测试
    //首个发布测试
    client.publish(topic2, "the first publish test");
    //订阅主题
    client.subscribe(topic1);

    client.publish(topic2,"1"); //发布“1” 占位
}//setup end


////////////////////////loop函数/////////////////////////////////////
void loop() {

//MQTT重连机制
//  if (!client.connected()) {
//    reconnect();
//  }

//MQTT不断监听信息 用于保持订阅状态
    client.loop();

//每隔两秒调用一次超声波函数 在内部调用发布函数
    long now = millis();
    if (now - lastMsg > 2000) {//延时2s
       lastMsg = now;
       push_Ultrasound_Water();
       KEY_PROS();//按键2S为一个检测周期 刚好
}
    


}


////////////////////////自定义函数/////////////////////////////////////

//用于接收消息
void callback(char *topic1, byte *payload, unsigned int length) {
    Serial.println("--------Start - Message arrived ----------");
    Serial.print("Message arrived in topic: ");
    Serial.println(topic1);
    String message;
    for (int i = 0; i < length; i++) {
        //payload 在参数里的类型是 byte*
        message = message + (char) payload[i];  // convert *byte to string
    }
    Serial.print("Message:"); 
    Serial.println(message); //需要语音播报出来
//    if (message == "on") { digitalWrite(LED, HIGH); Serial.println("LED已经打开"); }   // LED on
//    if (message == "off"){ digitalWrite(LED, LOW); Serial.println("LED已经关闭"); } // LED off
    Serial.println();
    Serial.println("--------End - Message arrived ----------");
}


//用于发送超声波测到的数据并在超声波测距过近提醒
void push_Ultrasound_Water() {
  

//光照检测  只本地
    Serial.println("--------Start - Light - detect----------");
    Serial.print("光照强度： "); 
    lightIntensity = shine();
    Serial.println(lightIntensity);  //串口监视器显示光照强度
    Serial.print("\n");  //回车
    if(lightIntensity < 60){
      digitalWrite(ledPinLight,HIGH);//当光照强度小于30，点亮LED D3引脚
    }
    else{
      digitalWrite(ledPinLight,LOW);
    }
    Serial.println("--------End - Light - detect----------");
    

    
////超声波和水位以“10，10.00”形式一起发布,英文逗号分割形成完整字符串发布
//    Serial.println("--------Start - Ultrasound&&Water - publish - ----------");
//    char text[20]; //长度20的字符串，还可以char *Buff ;
//    sprintf(text, "%d%s%lf", utlDistance, "  ,  " , waterHigh); 
//    client.publish(topic,text);
//    Serial.printf("Have published %s to the topic of cc36e70148924ef2bb2e1d477c24675f", text); 
//    Serial.println("--------End - Ultrasound&&Water - publish----------");
}


//光照强度映射函数
int shine(){
  int i=analogRead(A0);//光感模拟口接esp8266AO口
  i=1023-i;
  i=i/10.23-1;   //将光照强度设置为0-99
  return i;
}


//按键处理函数
void KEY_PROS()
{
  if(digitalRead(KEY)==0){
    delay(5);
    if(digitalRead(KEY)==0){ //如果接地了
      client.publish(topic2,"1"); //发布“1” 占位
      Serial.println("已经发送1到button主题.");
    }
  }
  
  else if(digitalRead(KEY)==1){//KEY接地为0 不接地为1
  
  }
  
//  switch (temp){
//    case 1:alarm();break; //插入接地 点亮 发送邮件
//    case 0: ;break; //再插入接地 再按一下 模拟显示端反馈后 再按一下再发送代表误触的邮件
//  }
  
}


 

```


## 几个需要注意的点
- 窗口不能最小化 否则抓到等大小的最上面的窗口画面
- 句柄要先检测之后填充更换 hwnd的值
- 硬件程序的按钮检测不要直接放在loop里面 放在2s一下里面，其中我第一个板子的发邮件得益于连接邮件服务比较慢 好像是放在loop也没事 等着有空试试改在2s一下的检测里面测试一下

## 待解决 待优化 #待办 
待解决：将硬件接收到的字符串的message进行语音播报
好像语音只能播报已经存好的MP3文件 那这样我可以存这样几种东西
'前方有' + '0 1 2 3 4 5' +'个人/辆汽车/...' 判断组合进行播放？

待优化：将ipcam的帧直接在python抓取 而不是抓取窗口的显示画面

# YOLO函数调用
## os库里面的popen()方法调用 - 读取识别信息 播报 #待办


参考调用：[YOLOv5在Django中调用_一个初学者^^的博客-CSDN博客](https://blog.csdn.net/x1114331429/article/details/122743811)


[python-os-popen-方法](0101%20毕设仓库/python-os-popen-方法.md)
![](201903040009images.aasts/image-20230409214708196.png)

![](201903040009images.aasts/image-20230409215257088.png)







[Python中os库里面的popen()方法_res = os.popen('curl -s cip.cc --connect-timeout 1_鲲鹏飞九万里的博客-CSDN博客](https://blog.csdn.net/hefrankeleyn/article/details/85098186#:~:text=%E6%A6%82%E8%BF%B0%20os.%20popen%20%28%29%20%E6%96%B9%E6%B3%95%20%E7%94%A8%E4%BA%8E%E4%BB%8E%E4%B8%80%E4%B8%AA%E5%91%BD%E4%BB%A4%E6%89%93%E5%BC%80%E4%B8%80%E4%B8%AA%E7%AE%A1%E9%81%93%E3%80%82%20%E5%9C%A8Unix%EF%BC%8CWindows%20%E4%B8%AD,%E4%BD%BF%E7%94%A8%E7%9A%84%E5%91%BD%E4%BB%A4%E3%80%82%20mode%20%E2%80%93%20%E6%A8%A1%E5%BC%8F%E6%9D%83%E9%99%90%E5%8F%AF%E4%BB%A5%E6%98%AF%20%E2%80%98r%E2%80%99%20%28%E9%BB%98%E8%AE%A4%29%20%E6%88%96%20%E2%80%98w%E2%80%99%E3%80%82)



## 可以放在view函数代码段参考
几个需要解决的问题：
- OS库 popen() 方法的使用
- cmd命令的替换
- 函数调用方式 不同python函数如何调用
- 只是打印出来了一般情况的（如图片的）信息 如果我换成识别视频的命令 视频去哪了
```
def getperson(url:str) -> int:
	'''
	处理图片
	:param url:图片地址
	:return: 图片中的人数
	'''
	cmd = r'python D:\pyproject\yolov5-django\detect.py --source ' + url + ' --classes 0 --exist-ok'
	text = os.popen(cmd).readlines()
	print(text)
	person = re.findall('.* (.*?) person', str(text))
	if len(person) == 0:
		print('图像内没有人')
		return int(0)
	else:
		print('一共有',person[0],'人') # 打印人数
		return int(person[0])

if __name__ == '__main__':
    getperson()
```

### 问题1 popen方法
引入库以及简单的认识：
[Python os.popen() 方法 | 菜鸟教程 (runoob.com)](https://www.runoob.com/python/os-popen.html)




---

`运行过程遇到的一些问题`

---

VS Code Python “Statements must be separated by newlines or semicolons“
![](201903040009images.aasts/image-20230409185450961.png)

![](201903040009images.aasts/image-20230409185527296.png)

加括号就行了 python3不加不行

---
![](201903040009images.aasts/image-20230409213529896.png)


---


### 问题2 调用格式
cmd格式：（项目下执行可以，系统cmd执行报错）

```
python D:\Desktop\yolov5-7.0\detect.py --weights yolov5s.pt --source D:/Desktop/image/bus.jpg  【--classes 0 --exist-ok】
```

cmd先切换盘符 再连续执行yolo测试是否正确 <span style="background:#ff4d4f"> 牛逼 正确了 下面可以readlines() 试试有没有结果了</span>

```
d: && python D:\Desktop\yolov5-7.0\detect.py --weights yolov5s.pt --source D:/Desktop/image/bus.jpg 
```

![](201903040009images.aasts/image-20230409224110804.png)

![](201903040009images.aasts/image-20230409231309186.png)


---


相对地址 正常情况执行的命令：【 用5s一般模复杂度型为例】
python detect.py --weights yolov5s.pt --source data/images/bus.jpg

参考地址 待修改：
```
cmd = r'python D:\pyproject\yolov5-django\detect.py --source ' + url + ' --classes 0 --exist-ok'
```


yolo主函数地址：
```
D:\Desktop\yolov5-7.0
```


自定义我的地址：
url自填充
```
cmd = r'python D:\Desktop\yolov5-7.0\detect.py --weights yolov5s.pt --source ' + url + ' --classes 0 --exist-ok'
```

以桌面一个文件夹内的图片为例

```
D:\Desktop\image\photo.jpg
```

![](201903040009images.aasts/image-20230409190451742.png)


### 代码测试存档


```
#!/usr/bin/python
# -*- coding: UTF-8 -*-

import os, sys, re

# yolo 调用
def getperson(url:str) -> int:
	'''
	处理图片
	:param url:图片地址
	:return: 图片中的人数
	'''
	cmd = r'python D:\Desktop\yolov5-7.0\detect.py --weights yolov5s.pt --source ' + url + ' --classes 0 --exist-ok'
	#下面这行不太对 不能读取写内存 在read之前的那个东西 
	text = os.popen(cmd).readlines()
	print('********************')
	print(text)
	print("********************")
	person = re.findall('.* (.*?) person', str(text))
	if len(person) == 0:
		print('图像内没有人')
		return int(0)
	else:
		print('一共有',person[0],'人') # 打印人数
		return int(person[0])

if __name__ == '__main__':
    getperson("D:/Desktop/image/bus.jpg")
```


```
#!/usr/bin/python
# -*- coding: UTF-8 -*-

import os, sys, re

# yolo 调用
def getperson(url:str) -> int:
	'''
	处理图片
	:param url:图片地址
	:return: 图片中的人数
	'''
	cmd = r'python D:\Desktop\yolov5-7.0\detect.py --weights yolov5s.pt --source ' + url + ' --classes 0 --exist-ok'
	#下面这行能读取写内存 在read之前的那个东西 
	text = os.popen(cmd,"r",50)
	print('********************')
	print(text)
	print("********************")
	person = re.findall('.* (.*?) person', str(text))
	if len(person) == 0:
		print('图像内没有人')
		return int(0)
	else:
		print('一共有',person[0],'人') # 打印人数
		return int(person[0])

if __name__ == '__main__':
    getperson("D:/Desktop/image/bus.jpg")
```

## 思路2 在yolo本身下功夫 保存在txt之类 #待办

[python根据yolov5检测得到的txt文件，截取目标框图片并保存_yolov5 目标截图_深度学习菜鸟的博客-CSDN博客](https://blog.csdn.net/qq_36756866/article/details/116762837)

[YOLOv3视频检测及检测结果保存（傻瓜式，不改代码，适用于将YOLOv3做黑盒使用的同学）_岳麓吹雪的博客-CSDN博客](https://blog.csdn.net/lin453701006/article/details/101349398)






# 前端显示识别画面
## 方案1 html直接写python代码 
[什么？可以在 HTML 中直接插入 Python 代码？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/510792410)


## 方案2 html调用cmd命令 - 仅ie 弹窗
[html网页调用cmd命令行并执行命令（亲测可用）_html执行cmd命令_王延凯的博客的博客-CSDN博客](https://blog.csdn.net/weixin_38468077/article/details/120508802)


```html
 
<html xmlns="http://www.w3.org/1999/xhtml">
    <head>
    <meta http-equiv="Content-Type" content="text/html; charset=gb2312" />
    <title>测试php+js调用cmd命令行</title>
    </head>
     
     
    <body>
     <a href="#" onclick="win_run(); return false;">调用cmd</a>
    </body>
     
    <script type="text/javascript">
    function win_run(){	
    var cmd=new ActiveXObject("WScript.Shell");
    cmd.run("cmd.exe /k d: && python D:/Desktop/yolov5-7.0/detect.py --weights yolov5s.pt --source http://admin:admin@192.168.127.245:8081 && activate py35 && python pr.py > result.txt");//百度搜索cmd多命令行一起写
    cmd=null;
     window.setTimeout('window.close();',3000);
    }
    </script>
    </html>
    
```

## 方案3 TensorFlow.js 调用yolo  👍
[简单使用TensorFlow.js在浏览器进行视频实时目标识别(基于YOLO V3) - iNick - 博客园 (cnblogs.com)](https://www.cnblogs.com/inick/p/13804411.html)

![](201903040009images.aasts/image-20230410152304662.png)

## 方案3 自己的实现想法
终端按一个按钮 发布一条命令 view函数抓取当前屏幕，截图之类（当前桌面运行着ipcam的无识别的画面 播放），文件读取 存在某个文件夹内

再调用popen()方法 cmd 识别 将识别出来的信息 存在字符串中 并发布出去  终端语音播报

### yolo cmd为空 未解决😥
目前未通的一些点：cmd 识别 将识别出来的信息 无法正常识别 打印为空 其他cmd命令正常  yolo为空
[Python获取CMD命令行输出结果 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/117495961)


### python抓屏 
需要改善的一个点：抓取当前屏幕，截图之类 能不能直接抓后台 不一定非得截屏当前【对视频帧的抓取并保存】‘=

### pyQT指定窗口截图  👍主推路线

---


 `Python 三种方法实现截图【详解+完整代码】` 
 第二种 PyQt 可以抓取 指定获取的窗口，即使窗口被遮挡。
 `参考1`
[(1条消息) Python 三种方法实现截图【详解+完整代码】_python截图_蚂蚁爱Python的博客-CSDN博客](https://blog.csdn.net/xff123456_/article/details/128501167?spm=1001.2101.3001.6650.5&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-5-128501167-blog-125820193.235%5Ev28%5Epc_relevant_t0_download&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-5-128501167-blog-125820193.235%5Ev28%5Epc_relevant_t0_download&utm_relevant_index=10)  


初始代码 全是 乱乱的 特点 会打印当前所有的窗口ID 然后图片是

```
# 先引入依赖包 pip install PyQt5
import win32gui
from PyQt5.QtWidgets import QApplication
import sys
 
hwnd_title = dict()
 
 
def get_all_hwnd(hwnd, mouse):
    if win32gui.IsWindow(hwnd) and win32gui.IsWindowEnabled(hwnd) and win32gui.IsWindowVisible(hwnd):
        hwnd_title.update({hwnd: win32gui.GetWindowText(hwnd)})

 
win32gui.EnumWindows(get_all_hwnd, 0)
# print(hwnd_title.items()) 打印的是hwnd值和对应的Title
for h, t in hwnd_title.items():
    if t != "":
        print(h, t)
 
# 程序会打印窗口的hwnd[检索窗口句柄]和title，有了title就可以进行截图了。 exe文件spy++获取class和Title 其实上面打印对应的hwnd了 这个可以省略
FrameClass = "OrpheusBrowserHost"
FrameTitle = "Catch My Breath - Kelly Clarkson"
hwnd = win32gui.FindWindow(FrameClass, FrameTitle)
print(hwnd)
app = QApplication(sys.argv)
screen = QApplication.primaryScreen()
img = screen.grabWindow(hwnd).toImage()
img.save("screenshot.jpg")

 
```


我改好的程序 
一些备注：

```
# 先引入依赖包 pip install PyQt5
import win32gui
import win32con
from PyQt5.QtWidgets import QApplication
from PIL import ImageGrab

hwnd_title = dict()
 
 # 这一段和下一段为了打印所有的title对应的hwnd的 只有第一次用得到 把hwnd填入赋值即可
def get_all_hwnd(hwnd, mouse):
    if win32gui.IsWindow(hwnd) and win32gui.IsWindowEnabled(hwnd) and win32gui.IsWindowVisible(hwnd):
        hwnd_title.update({hwnd: win32gui.GetWindowText(hwnd)})

 
win32gui.EnumWindows(get_all_hwnd, 0)
# print(hwnd_title.items()) 打印的是hwnd值和对应的Title
for h, t in hwnd_title.items():
    if t != "":
        print(h, t)
 
# 程序会打印窗口的hwnd[检索窗口句柄]和title，有了title就可以进行截图了。 spy++获取class和Title 其实上面打印对应的hwnd了 这个可以省略
FrameClass = "OrpheusBrowserHost"
FrameTitle = "Catch My Breath - Kelly Clarkson"
hwnd = win32gui.FindWindow(FrameClass, FrameTitle)
print(hwnd)

# hwnd = win32gui.FindWindow(None, 'C:\Windows\system32\cmd.exe')
win32gui.ShowWindow(hwnd, win32con.SW_RESTORE)  # 强行显示界面后才好截图
win32gui.SetForegroundWindow(hwnd)  # 将窗口提到最前
#  裁剪得到全图
game_rect = win32gui.GetWindowRect(hwnd)
src_image = ImageGrab.grab(game_rect)
# src_image = ImageGrab.grab((game_rect[0] + 9, game_rect[1] + 190, game_rect[2] - 9, game_rect[1] + 190 + 450))
src_image.show()
src_image.save("screenshot.jpg")
```

`我改好的 不用额外软件的实现方式1 刚开始对应的窗口不能最小化 最好是显示在桌面最上方`
我测试发现ipcam的最开始放在最上面是可以的 
网易云等其他的应该是只要不是最小化 还在桌面的某个层级都是可以的
无论如何 都不能最小化掉 否则只有对应窗口大小的最上一层的图像情况

```
# 先引入依赖包 pip install PyQt5
import win32gui
import win32con
from PyQt5.QtWidgets import QApplication
from PIL import ImageGrab

hwnd_title = dict()
 
 
def get_all_hwnd(hwnd, mouse):
    if win32gui.IsWindow(hwnd) and win32gui.IsWindowEnabled(hwnd) and win32gui.IsWindowVisible(hwnd):
        hwnd_title.update({hwnd: win32gui.GetWindowText(hwnd)})

 
win32gui.EnumWindows(get_all_hwnd, 0)
# print(hwnd_title.items()) 打印的是hwnd值和对应的Title
for h, t in hwnd_title.items():
    if t != "":
        print(h, t)
 
# 程序会打印窗口的hwnd[检索窗口句柄]和title，有了hwnd填入下面的变量就可以进行截图了
hwnd = 463470 #上面获取后自己填入对应窗口的hwnd 第一列
print(hwnd)

win32gui.ShowWindow(hwnd, win32con.SW_RESTORE)  # 强行显示界面后才好截图
win32gui.SetForegroundWindow(hwnd)  # 将窗口提到最前
#  裁剪得到全图
game_rect = win32gui.GetWindowRect(hwnd)
src_image = ImageGrab.grab(game_rect)
src_image.show()
src_image.save("screenshot.jpg")
```


`我改好的 用额外的软件的实现方式2`
[(1条消息) pyQT指定窗口截图_chuange6363的博客-CSDN博客](https://blog.csdn.net/chuange6363/article/details/100753665)  `参考2`
[(1条消息) 【Python】win32gui.Findwindow(parm1,parm2)窗口句柄获取_ztmajor的博客-CSDN博客](https://blog.csdn.net/ztmajor/article/details/105376319)

需要用到软件spy++ 获取
FrameClass = "OrpheusBrowserHost"
FrameTitle = "Catch My Breath - Kelly Clarkson"
![](201903040009images.aasts/image-20230411221211245.png)

![](201903040009images.aasts/image-20230411221244923.png)

![](201903040009images.aasts/image-20230411221301904.png)

![](201903040009images.aasts/image-20230411221311903.png)


```
# 先引入依赖包 pip install PyQt5
import win32gui
import win32con
from PyQt5.QtWidgets import QApplication
from PIL import ImageGrab

hwnd_title = dict()
 
 
def get_all_hwnd(hwnd, mouse):
    if win32gui.IsWindow(hwnd) and win32gui.IsWindowEnabled(hwnd) and win32gui.IsWindowVisible(hwnd):
        hwnd_title.update({hwnd: win32gui.GetWindowText(hwnd)})

 
win32gui.EnumWindows(get_all_hwnd, 0)
# print(hwnd_title.items()) 打印的是hwnd值和对应的Title
for h, t in hwnd_title.items():
    if t != "":
        print(h, t)
 
# clas 和 Title是经过spy++ 获取的 填到下面
FrameClass = "OrpheusBrowserHost"
FrameTitle = "Catch My Breath - Kelly Clarkson"
hwnd = win32gui.FindWindow(FrameClass, FrameTitle)
print(hwnd)

win32gui.ShowWindow(hwnd, win32con.SW_RESTORE)  # 强行显示界面后才好截图
win32gui.SetForegroundWindow(hwnd)  # 将窗口提到最前
#  裁剪得到全图
game_rect = win32gui.GetWindowRect(hwnd)
src_image = ImageGrab.grab(game_rect)
src_image.show()
src_image.save("screenshot.jpg")
```


---
### win32gui.Findwindow(param1,param2)

[(1条消息) 【Python】win32gui.Findwindow(parm1,parm2)窗口句柄获取_ztmajor的博客-CSDN博客](https://blog.csdn.net/ztmajor/article/details/105376319)
- param1:需要传入窗口的类名
- param2:需要传入窗口的标题


---

















# 封装调用相关 /基础知识
[yolov5 python API（供其他程序调用）_yolov5 api_普通网友的博客-CSDN博客](https://blog.csdn.net/m0_67401499/article/details/125346054?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0-125346054-blog-123208715.235^v28^pc_relevant_t0_download&spm=1001.2101.3001.4242.1&utm_relevant_index=3)


## python文件操作 读写文件
![](201903040009images.aasts/image-20230409220657518.png)


## python 字符串转换为int类型的两种方法（面试题）
[python 字符串转换为int类型的两种方法（面试题）_python字符型转为int型_/乾坤未定/的博客-CSDN博客](https://blog.csdn.net/qwertyuiopasdfgg/article/details/89307128)







# 一些报错和细节

## 空格和tab混用 print会报错
![](201903040009images.aasts/image-20230409221459274.png)


## 难解决 重大问题标注 

![](201903040009images.aasts/image-20230409223912602.png)



![](201903040009images.aasts/image-20230409223808851.png)


![](201903040009images.aasts/image-20230409223753571.png)


## pycharm索引自动更新
---

[Python: PyCharm 启动后总是不停的 updating indexes..._pycharm updating indexes_RaySunWHUT的博客-CSDN博客](https://blog.csdn.net/qq_40994260/article/details/113622913)


